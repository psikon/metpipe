[General]

# dir for the FastQC reports (inside the cmd given output dir)
quality_dir = quality_reports

# dir for TrimGalore (inside the cmd given output dir)
trim_dir = trimmed

# dir for Flash (inside the cmd given output dir)
concat_dir = concatinated

# dir for MetaVelvet (inside the cmd given output dir)
assembly_dir = assembled

# dir for Blastn (inside the cmd given output dir)
blastn_dir = blasted

# dir for MetaCV (inside the cmd given output dir)
metacv_dir = metacv

# dir for DB Parser (inside the cmd given output dir)
parsed_db_dir = analysis

# dir for Annotated DB (inside the cmd given output dir)
annotated_db_dir = analysis

# dir for subseted DB (inside the cmd given output dir)
subseted_db_dir = analysis

# dir for krona reports (inside the cmd given output dir)
krona_report = analysis

# dir for the log files (inside the cmd given output dir)
log_dir = log

## PreProcessing options ##
 
[FastQC]
path = /home/psehnert/daten/metagenomics/scripts/metpipe/bin
  
# Disable grouping of bases for reads > 50bp. All reports will show data for every base in the read.
nogroup = False

# Specifies a file containg a list of contaminants to screen overrepresented sequences against. Structure:  
# contaminants name[tab]sequence
contaminants = 

# length of Kmer to look for in the Kmer content module. between 2-10, default = 5  
kmers = 5

[FastX]			                 
path = /home/psehnert/daten/metagenomics/scripts/metpipe/bin

[TrimGalore]
path = /home/psehnert/daten/metagenomics/scripts/metpipe/bin

# Trim low-quality ends from reads in addition to adapter removal. default = 20
quality = 18			

# use ASCII+33 or ASCII+64 quality scores (Sanger/Illumina 1.9+/1.5 encoding) 33 or 64
phred = 33         
 
# Adapter sequence to be trimmed. default = the first 13 bp of the Illumina adapter 'AGATCGGAAGAGC'
adapter = 	
		
# Optional adapter sequence to be trimmed off read 2 of paired-end files (requires paired option)
adapter2 =
		
# Overlap with adapter sequence required to trim a sequence. Defaults to a very stringent setting of '1', i.e. 
# even a single bp of overlapping sequence will be trimmed of the 3' end of any read.
stringency = 	

# Maximum allowed error rate (no. of errors divided by the length of the matching region) (default: 0.1) 
error_rate = 0.1				
							
# Discard reads that became shorter than length INT because of either quality or adapter trimming. A value 
# of '0' effectively disables this behaviour. Default: 20 bp.
length = 150		
	
# Performs length trimming  for paired-end files. Both sequences of a sequence pair are required to have a 
# minimum length (option length ). If only one read passes this length threshold the other read can be rescued 
# (see option retain_unpaired). Using lets you discard too short read pairs without disturbing the 
# sequence-by-sequence order of FastQ files which is required by many aligners.
paired = True
	
# If only one of the two paired-end reads became too short, the longer read will be written to either 
# '.unpaired_1.fq' or '.unpaired_2.fq' output files
retain_unpaired	= 	True		

# Unpaired single-end read length cutoff needed for read 1 to be written to '.unpaired_1.fq' output file. 
# These reads may be mapped in single-end mode. Default: 35 bp.
length_1 = 

# Unpaired single-end read length cutoff needed for read 2 to be written to '.unpaired_2.fq' output file. 
# These reads may be mapped in single-end mode. Default: 35 bp.
length_2 = 

# Trims 1 bp off every read from its 3' end. This may be needed for FastQ files that are to be aligned as 
# paired-end data with Bowtie. This is because Bowtie (1) regards alignments like this: 
# R1 --------------------------->     or this:    ----------------------->  R1
# R2 <---------------------------                       <-----------------  R2
# as invalid (whenever a start/end coordinate is contained within the other read).
trim1 = False

## Assembly options ##

[FLASH]
path = /home/psehnert/daten/metagenomics/scripts/metpipe/bin

# The minimum required overlap length between two
# reads to provide a confident overlap.  (default: 10bp)
min-overlap = 10   

# Maximum overlap length expected in approximately 90% of 
# read pairs.  It is by default set to 70bp, which works well 
# for 100bp reads generated from a 180bp library, assuming 
# a normal distribution of fragment lengths.  Overlaps longer 
# than the maximum overlap parameter are still considered as good
# overlaps, but the mismatch density (explained below) is 
# calculated over the first max_overlap bases in the overlapped 
# region rather than the entire overlap.  
# (Default: 70bp, or calculated from the specified read length, 
# fragment length, and fragment length standard deviation)
max-overlap = 150   

# Maximum allowed ratio between the number of mismatched base pairs 
# and the overlap length. Two reads will not be combined with a 
# given overlap if that overlap results in a mismatched base density
# higher than this value.  Note: Any occurence of an 'N' in either 
# read is ignored and not counted towards the mismatches or overlap 
# length.  Our experimental results suggest that higher values of
# the maximum mismatch density yield larger numbers of correctly 
# merged read pairs but at the expense of higher numbers of incorrectly
# merged read pairs.  (Default: 0.25)
max-mismatch-density =
                          
# The smallest ASCII value of the characters used to represent quality 
# values of bases in FASTQ files. It should be set to either 33, which 
# corresponds to the later Illumina platforms and Sanger platforms, 
# or 64, which corresponds to the arlier Illumina platforms. (default: 33)
phred-offset = 33
                          
# Average read length, fragment length, and fragment standard deviation.  
# These are convenience parameters only, as they are only used for calculating 
# the maximum overlap (--max-overlap) parameter. The maximum overlap is 
# calculated as the overlap of average-length reads from an average-size 
# fragment plus 2.5 times the fragment length standard deviation.  
# The default values are -r 100, -f 180, and -s 18, so this works out to a 
# maximum overlap of 70 bp.  If --max-overlap is specified, then the
# specified value overrides the calculated value.
# If you do not know the standard deviation of the fragment library, you can 
# probably assume that the standard deviation is 10% of the average fragment
# length.
read-len=250
fragment-len=400
fragment-len-stddev=40
    
# Instead of requiring files MATES_1.FASTQ and MATES_2.FASTQ, allow a single 
# file MATES.FASTQ that has the paired-end reads interleaved.  Specify "-"
# to read from standard input.                     
interleaved-input = False

#  Write the uncombined pairs in interleaved format.
interleaved-output = True

[Velvet]
path = /home/psehnert/daten/metagenomics/scripts/metpipe/bin

## velveth options ##

kmer = 85

# File layout options for paired reads (only for fasta and fastq formats):
# interleaved	: File contains paired reads interleaved in the one file (default)
# separate		: Read 2 separate files for paired reads
file_layout = interleaved

# Read type options: short, shortPaired, short2, shortPaired2, long, longPaired, reference
read_type = short

# for strand specific transcriptome sequencing data (default: off)
strand_specific = True

# reuse Sequences file (or link) already in directory (no need to provide original filenames in this case (default: off)
reuse_Sequences	= False

# simply prepare Sequences file, do not hash reads or prepare Roadmaps file (default: off)
noHash = False

# create binary CnyUnifiedSeq file (default: off)
create_binary = False 

## velvetg options ##

# removal of low coverage nodes AFTER tour bus or allow the system to infer it (default: no removal)
# <floating-point|auto>
cov_cutoff =  

# expected distance between two paired end reads (default: no read pairing)
#ins_length = 

# tracking of short read positions in assembly (default: no tracking)
read_trkg = False
	
# minimum contig length exported to contigs.fa file (default: hash length * 2)
min_contig_lgth = 250

# expected coverage of unique regions or allow the system to infer it (default: no long or paired-end read resolution)
# <floating point|auto>
exp_cov = auto
		
# removal of nodes with low long-read coverage AFTER tour bus (default: no removal)
# <floating-point>
long_cov_cutoff = 
	
#expected distance between two long paired-end reads (default: no read pairing)
ins_length_long = 
	
# est. standard deviation of respective dataset (default: 10% of corresponding length)
ins_length_sd =

# scaffolding of contigs used paired end information (default: on)	
scaffolding = False
	
# maximum length in base pair of bubble (default: 100)
max_branch_length = 

# maximum divergence rate between two branches in a bubble (default: 0.2)
max_divergence = 
	
# maximum number of gaps allowed in the alignment of the two branches of a bubble (default: 3)
max_gap_count = 

# minimum number of paired end connections to justify the scaffolding of two long contigs (default: 5)
min_pair_count = 
	
# removal of high coverage nodes AFTER tour bus (default: no removal)
max_coverage =  

# minimum coverage required for confident regions of contigs (default: 1)
coverage_mask = 

# minimum number of long reads required to merge contigs (default: 2)
long_mult_cutoff =

# export unused reads in UnusedReads.fa file (default: no)
unused_reads = True

# export a summary of contig alignment to the reference sequences (default: no)
alignments = True

# export the long nodes which were eliminated by the coverage filters (default: no)
exportFiltered = False 

# remove all the paired end connections which less than the specified fraction of the expected count (default: 0.1)
paired_exp_fraction = 
	
# for mate-pair libraries, indicate that the library might be contaminated with paired-end reads (default: no)
shortMatePaired = False  

# preserve sequences with long reads in them (default: no)
conserveLong = False

[MetaVelvet]
path = /home/psehnert/daten/metagenomics/scripts/metpipe/bin

## meta-velvetg options ##

# discard chimera sub-graph (default: no)
discard_chimera = False

# maximum allowable chimera rate (default: 0.0)
max_chimera_rate = 0.0

# standard deviation of repeat node coverages (default: 0.1)
repeat_cov_sd = 0.1

# minimum node length required for repeat resolution (default: 0)
min_split_length = 0

# minimum allowable number of consistent paired-end connections (default: 1)
valid_connections = 1

# maximum allowable number of inconsistent paired-end connections (default: 0)
noise_connections = 0

# use paired-end connections for graph splitting (default: yes)
use_connections = False

# report sequences around repeat nodes (default: no)
report_split_detail = False

# report node sequences for each subgraph (default: no)
report_subgraph = False

# expected coverages for each species in microbiome (default: auto) 
# ex) -exp_covs 214_122_70_43_25_13.5 coverage values should be sorted in a descending order
exp_covs_meta = auto

# minimum peak coverage (default: 0) 
min_peak_cov = 0

# maximum peak coverage (default: 500)
max_peak_cov = 500

# bin width of peak coverage histogram (default: 1)	
histo_bin_width = 1

# signal-noise ratio to remove peak noises (default: 10)
histo_sn_ratio = 10

# export assembly to AMOS file (default: no export)
amos_file = False

# minimum coverage required for confident regions of contigs (default: 1)
coverage_mask = 1

# export unused reads in UnusedReads.fa file (default: no)
unused_reads_meta = True

# export a summary of contig alignment to the reference sequences (default: no)
alignments_meta = True

# export the long nodes which were eliminated by the coverage filters (default: no)
exportFiltered_meta = False

# remove all the paired end connections which less than the specified fraction of the expected count (default: 0.1)
paired_exp_fraction_meta = 0.1

## Annotate ##

[MetaCV]
path = /home/psehnert/daten/metagenomics/scripts/metpipe/bin

db = /home/psehnert/daten/metagenomics/scripts/metpipe/db/metacv

# name of the files
name = metpipe

# classify:

# sequence type, default: dna
seq = dna

# clustering mode, default: upgma
mode = upgma

# ORF-search mode, default: optimal
orf = optimal

# res2table: 

# total # of reads in each sample (0 to ignore normalization), default: 1000000
total_reads=1000000

# minimal read quality, default: 20.00
min_qual=20.00

# use taxonomic ID of top-hit organism or latest common ancestor, default: lca
taxon=lca 

[blastn]
path = /home/psehnert/daten/metagenomics/scripts/metpipe/bin

# location of db
db = /home/psehnert/daten/metagenomics/scripts/metpipe/db/blast

# --- Input Options --- 

# Location on the query sequence in 1-based offsets (Format: start-stop)
#  <String>
query_loc = 


# Query strand(s) to search against database/subject (default = both)
# <String, both, minus, plus>
strand =  

# --- Alignment Options ---

# expectation value (E) threshold for saving hits (default = 10)
# <Real>
evalue = 

# word size for wordfinder algorithm (length of best perfect match)
# <Integer>, >=4 
word_size =

# Cost to open a gap 
# <Integer>
gapopen =

# Cost to extend a gap 
# <Integer>
gapextend =

# Penalty for a nucleotide mismatch 
# <Integer>, <=0
penalty =

# Reward for a nucleotide match 
# <Integer>, >=0
reward =

# --- Query filtering options ---

# filter query sequence with DUST (default = 20 64 1)
# (Format: 'yes', 'level window linker', or 'no' to disable)
# <String>
dust = 

# BLAST database containing filtering elements (i.e.: repeats)
# <String>  
filtering_db = 

# enable WindowMasker filtering using a Taxonomic ID
# <Integer>
window_masker_taxid =

# Enable WindowMasker filtering using this repeats database
# <String>
window_masker_db = 

# apply filtering locations as soft masks (default = true)
# (True or False)
soft_masking =

# use lower case filtering in query and subject sequence(s)?
# (True or False)
lcase_maskingm = False   
   
# --- Restrict search or results ---

# Percent identity
# <Real>, 0, ..., 100
perc_identity = 90.0

# restrict search of database to list of GI's
# incompatible with:  negative_gilist, seqidlist
# <String>
gilist = 

# restrict search of database to list of SeqId's
# incompatible with: gilist, negative_gilist
# <String>
seqidlist = 

# restrict search of database to everything except the listed GIs
# incompatible with:  gilist, seqidlist
# <String>
negative_gilist =  

# filtering algorithm ID to apply to the BLAST database as soft masking
# incompatible with:  db_hard_mask
# <String>
db_soft_mask =  

# filtering algorithm ID to apply to the BLAST database as hard masking
# incompatible with:  db_soft_mask
# <String>
db_hard_mask = 

# if the query range of a hit is enveloped by that of at least this many
# higher-scoring hits, delete the hit
# incompatible with:  best_hit_overhang, best_hit_score_edge
# <Integer>, >=0
culling_limit =

# best_hit_overhang 
# Best Hit algorithm overhang value (recommended value: 0.1)
# incompatible with:  culling_limit
# <Real>, >=0 and =<0.5
best_hit_overhang =
    
# Best Hit algorithm score edge value (recommended value: 0.1)
# incompatible with:  culling_limit
# <Real>, >=0 and =<0.5
best_hit_score_edge =  
 
# Maximum number of aligned sequences to keep (default = 500)
# incompatible with:  num_descriptions, num_alignments and not applicable for outfmt <= 4  
# <Integer>, >=1
max_target_seqs =

# --- Statistical options ---

# Effective length of the database 
# <Int8>
dbsize =

# Effective length of the search space
# <Int8>, >=0
searchsp = 

# Override maximum number of HSPs per subject to save for ungapped searches
# (0 means do not override) (default = 0)
# <Integer>, >=0
max_hsps_per_subject =

# --- Search strategy options ---

# Search strategy to use <File>
import_search_strategy = 

# --- Extension options ---

# X-dropoff value (in bits) for ungapped extensions
# <Real>
xdrop_ungap =

# X-dropoff value (in bits) for preliminary gapped extensions
# <Real>
xdrop_gap =

# X-dropoff value (in bits) for final gapped alignment
# <Real>
xdrop_gap_final = 

# Use non-greedy dynamic programming extension  
# (True or False)
no_greedy = False
   
# Minimum raw gapped score to keep an alignment in the preliminary gapped and
# traceback stages
# <Integer>
min_raw_gapped_score = 
 
# Perform ungapped alignment only?
# (True or False)
ungapped = False

# Multiple hits window size, use 0 to specify 1-hit algorithm
# <Integer>, >=0
window_size =

# Number of off-diagonals to search for the 2nd hit, use 0 to turn off
# (default = 0) <Integer>, >=0
off_diagonal_range =

# --- Formatting options ---

# alignment view options:
# 	  0 = pairwise,
#     1 = query-anchored showing identities,
#     2 = query-anchored no identities,
#     3 = flat query-anchored, show identities,
#     4 = flat query-anchored, no identities,
#     5 = XML Blast output,
#     6 = tabular,
#     7 = tabular with comment lines,
#     8 = Text ASN.1,
#     9 = Binary ASN.1,
#    10 = Comma-separated values,
#    11 = BLAST archive format (ASN.1) 
# IMPORTANT FOR METPIPE: only 5 = XML can be completly used from Analysis
# module, 6 = tabular for simple Krona Pie Chart
outfmt =  5

# Show NCBI GIs in deflines? (True or False)
show_gis = False
 
# Number of database sequences to show one-line descriptions for (default = 500) 
# <Integer>, >=0
# Not applicable for outfmt > 4 and incompatible with: max_target_seqs
num_descriptions = 

# Number of database sequences to show alignments for (default = 250) 
# <Integer>, >=0
# incompatible with:  max_target_seqs
num_alignments =  

# Produce HTML output? (True or False)
html = False 

# --- Miscellaneous options ---

# Should the query and subject defline(s) be parsed?
# (True or False)
parse_deflines = False

[blastParser]
path = /home/psehnert/daten/metagenomics/scripts/metpipe/bin

# name of the parsed blast db
name = blastn
# Number of hits parsed. Default [20] (set [-1] for all)
max_hit = 100

# Number of hsps parsed. Default [20] (set [-1] for all)
max_hsp = 100

# After <n> parsed queries the data is dumped to the SQLite DB. (default = 1000)
reset_at = 1000

[Taxonomical Annotation]
taxon_db = /home/psehnert/daten/metagenomics/scripts/metpipe/db/taxonomy

# query coverage for hit filtering [default= 0.5]
coverage = 0.5

# bitscore tolerance for hsp filtering [default= 0.98]
bitscore = 0.98

# name of the taxonomical annotated db
name = annotated


[Subsetting of Database]
taxon_db = /home/psehnert/daten/metagenomics/scripts/metpipe/db/taxonomy

# classifier for subsetting, e.g 'bacteria'
classifier = bacteria, eukaryota

# bitscore tolerance for hsp filtering [default= 0.98]
bitscore = 0.98

# taxonomical rank for subsetting (must be specific for classifier and in the same
# order like classifier!)
rank = superkingdom, superkingdom


[Krona Tools]
path = /home/psehnert/daten/metagenomics/scripts/metpipe/bin

# location of the krona installation, if not installed in metpipe/ext/krona
install_dir = 

# name of the outputfile
filename = metpipe

# Name of the highest level. [Default: 'Root']
highest_level = Root  

# Include a wedge for queries with no hits
no_hits_wedge =      

# Pick from the best hits randomly instead of finding the lowest common ancestor
best_hit_random = False          

# Use percent identity for average scores instead of log[10] e-value.
use_perc_ident = True

# Use bit score for average scores instead of log[10] e-value.
use_bitscore = False

# Maximum depth of wedges to include in the chart
max_depth = 

# Allow taxa with ranks labeled "no rank".
allow_no_rank = False           

# Hue (0-360) for "bad" scores. [Default: '0']
bad_scores = 0  

# Hue (0-360) for "good" scores. [Default: '120']
good_scores = 120

# Create a local chart, which does not require an internet connection to view 
# (but will only work on this computer). 
local = False

# URL of Krona resources. [Default: 'http://krona.sourceforge.net']
krona_res =           

# Url to send query IDs to (instead of listing them) for each wedge. 
# The query IDs will be sent as a comma separated list in the POST variable 
# "queries", with the current dataset index (from 0) in the POST variable "dataset". 
# The url can include additional variables encoded via GET.
query_url = 

# E-value factor for determining "best" hits. Hits with e-values that are within this 
# factor of the highest scoring hit will be included when computing the lowest common 
# ancestor (or picking randomly if -r is specified). [Default: '10']
e_value = 10 




